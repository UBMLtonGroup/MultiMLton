<HTML
><HEAD
><TITLE
>The Config Layer</TITLE
><META
NAME="GENERATOR"
CONTENT="Modular DocBook HTML Stylesheet Version 1.59"><LINK
REL="HOME"
TITLE="Unix System Programming with Standard ML"
HREF="index.html"><LINK
REL="UP"
TITLE="The Swerve Detailed Design"
HREF="c4671.html"><LINK
REL="PREVIOUS"
TITLE="The IETF Layer"
HREF="x5496.html"><LINK
REL="NEXT"
TITLE="The Common Layer"
HREF="x5914.html"><LINK
REL="STYLESHEET"
TYPE="text/css"
HREF="book.css"></HEAD
><BODY
CLASS="SECT1"
BGCOLOR="#FFFFFF"
TEXT="#000000"
LINK="#0000FF"
VLINK="#840084"
ALINK="#0000FF"
><DIV
CLASS="NAVHEADER"
><TABLE
WIDTH="100%"
BORDER="0"
CELLPADDING="0"
CELLSPACING="0"
><TR
><TH
COLSPAN="3"
ALIGN="center"
>Unix System Programming with Standard ML</TH
></TR
><TR
><TD
WIDTH="10%"
ALIGN="left"
VALIGN="bottom"
><A
HREF="x5496.html"
>Prev</A
></TD
><TD
WIDTH="80%"
ALIGN="center"
VALIGN="bottom"
>Chapter 9. The Swerve Detailed Design</TD
><TD
WIDTH="10%"
ALIGN="right"
VALIGN="bottom"
><A
HREF="x5914.html"
>Next</A
></TD
></TR
></TABLE
><HR
ALIGN="LEFT"
WIDTH="100%"></DIV
><DIV
CLASS="SECT1"
><H1
CLASS="SECT1"
><A
NAME="AEN5681"
>The Config Layer</A
></H1
><P
>This layer implements modules that parse the server's configuration files.
This includes the MIME types file. It does not include the authorisation
files for user names and passwords. See <A
HREF="x5210.html#DTLNODEAUTH"
>the section called <I
>The NodeAuth Module</I
></A
> for
more information on those.</P
><P
>The configuration file is complex enough that I've used an ML-Yacc
parser. The ML-Yacc system is simple enough to use that it can be
comfortably used for small jobs like this. The ConfigTypes module defines
the types for the parse tree for the main configuration file.</P
><P
>Most of the code is in the Config module. I'll describe that first.
Most of it is just a lot of string handling and checking of parameters
for correctness so I'll skim lightly over that.</P
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="DTLCONFIG"
>The Config Module - Interface</A
></H2
><P
>First here are the types that describe the server's configuration.</P
><TABLE
BORDER="0"
BGCOLOR="#d0ffff"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="PROGRAMLISTING"
>(*  This is a simplified form of URLPath with just the parts.
    These paths are case-sensitive and so are stored in the
    original case.
*)
type NodePath = string list


(*  Required parameters are stored as strings with "" for an undefined
    value.  Optional ones as string option.
*)
datatype ServerConfig = ServerConfig of {
            server_root:    string,
            config_dir:     string,
            var_dir:        string,
            tmp_dir:        string,
            doc_dir:        string,
            cgi_dir:        string,
            mime_file:      string,
            error_log:      string,
            dir_index:      string,

            log_level:      Log.Level,

            run_user:       string option,
            run_group:      string option,

            conn_timeout:   int option,
            max_clients:    int option,
            max_tmp_space:  int option,
            max_req_size:   int option,

            listen_host:    string option,
            listen_port:    int,
            server_name:    string
            }</PRE
></TD
></TR
></TABLE
><P
>The server configuration is described by the <TT
CLASS="COMPUTEROUTPUT"
>ServerConfig</TT
>
type. It is held in a static variable in the Config module and fetched
by the <TT
CLASS="COMPUTEROUTPUT"
>getServerConfig</TT
> function. It is just a big record of all
of the parameters that apply to the server as a whole, as described in
<A
HREF="x3464.html#SERVERPARAMS"
>the section called <I
>The Server Parameters</I
> in Chapter 8</A
>.</P
><P
>A node configuration is described by the <TT
CLASS="COMPUTEROUTPUT"
>NodeConfig</TT
> type.
See <A
HREF="x3464.html#NODEPARAMETERS"
>the section called <I
>The Node Parameters</I
> in Chapter 8</A
> for more information on these
configuration parameters.  </P
><TABLE
BORDER="0"
BGCOLOR="#d0ffff"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="PROGRAMLISTING"
>datatype NodeConfig = NodeConfig of {
            path:       NodePath,
            kind:       NodeKind,
            options:    NodeOptionFormula list,
            auth:       NodeAuth
            }

and NodeKind = 
        NodeIsDir of {
            path:   string          (* directory path *)
            }

    |   NodeIsBuiltin of {
            name:   string
            }

    |   NodeIsScript of {
            path:   string
            }

(*  This is a subset of NodeConfig for .swerve files. *)
and SwerveConfig = SwerveConfig of {
            options:    NodeOptionFormula list,
            auth:       NodeAuth
            }

and NodeOptionFormula =
        NOFInherit
    |   NOFAll
    |   NOFNone
    |   NOFAdd of NodeOption
    |   NOFSub of NodeOption


and NodeOption =
        NodeExecCGI
    |   NodeFollowSymLinks
    |   NodeWithSubDirs


and NodeAuth = 
        NodeBasic of {
            realm:      string,
            user_file:  string,     (* path to the user file *)
            group_file: string,     (* path to the group file *)
            users:      string list,(* users to allow *)
            groups:     string list (* groups to allow *)
            }

    |   NodeNoAuth</PRE
></TD
></TR
></TABLE
><P
>The options for a node are described by a formula. This neatly describes
how the options of a node can be computed from those of its parent by
interpreting the formula. (The <TT
CLASS="COMPUTEROUTPUT"
>NodeExecCGI</TT
> option is a left-over
from an earlier design.  It is not used anymore).</P
><P
>The <TT
CLASS="COMPUTEROUTPUT"
>NodeAuth</TT
> type describes the authorisation parameters in
a straight-forward way. Extra kinds of authorisation can be added to
this type.</P
><P
>Each directory that implements a node can have a <TT
CLASS="COMPUTEROUTPUT"
>.swerve</TT
> file that
provides more parameters, mainly for authorisation. The contents of this
file is described by the <TT
CLASS="COMPUTEROUTPUT"
>SwerveConfig</TT
> type.  Having a separate
type allows parameters unique to this file to be added in the future and
besides, the path and kind parameters are not relevant.</P
><P
>Here are the main functions of the module interface for the configuration
parameters.</P
><TABLE
BORDER="0"
BGCOLOR="#d0ffff"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="PROGRAMLISTING"
>val processConfig:      string -&#62; unit

val haveServerConfig:   unit -&#62; bool

(*  This is not defined if the processConfig() has not succeeded. *)
val getServerConfig:    unit -&#62; ServerConfig

(*  Return a list of all of the node configurations. 
*)
val getNodeConfigs:     unit -&#62; NodeConfig list

(*  This reads a .swerve file and returns the configuration or
    NONE if it wasn't parsable.
    The Io exception will be raised if the file cannot be read.
*)
val processNodeFile:    string -&#62; SwerveConfig option

(*  This returns the node configuration from the main configuration
    file if the node path appeared exactly in the file.
*)
val findNodeConfig:    NodePath -&#62; NodeConfig option</PRE
></TD
></TR
></TABLE
><P
>The main entry point is <TT
CLASS="COMPUTEROUTPUT"
>processConfig</TT
> which is called from the Main
module as soon as the <TT
CLASS="COMPUTEROUTPUT"
>-f</TT
> command line option is read.  This reads
the configuration files and saves the information in the static variables.
If there are any errors then these are reported on standard error and
the server configuration will not be saved.</P
><P
>The <TT
CLASS="COMPUTEROUTPUT"
>haveServerConfig</TT
> function tests that the parsing was
successful. If so then some of the parameters are poked into
global variables, for example the logging file and level.  The
<TT
CLASS="COMPUTEROUTPUT"
>getServerConfig</TT
> function can then be called from anywhere in the
server to get the configuration.  Since this information is immutable
it can be safely called from any thread.</P
><P
>The node configurations are stored separately as a list in no
particular order.  The <TT
CLASS="COMPUTEROUTPUT"
>getNodeConfigs</TT
> function fetches the list.
Alternatively the <TT
CLASS="COMPUTEROUTPUT"
>findNodeConfig</TT
> function can be used to get a
particular node if its configuration path is known.  But the main use
for these configuration records is to build the resource store tree
(see <A
HREF="x5210.html#DTLSTORE"
>the section called <I
>The Store Module</I
></A
>) and this uses the whole list.</P
><P
>The <TT
CLASS="COMPUTEROUTPUT"
>processNodeFile</TT
> is used to parse a <TT
CLASS="COMPUTEROUTPUT"
>.swerve</TT
> file. Errors
are logged in the usual way.  The result is returned if there was no
error. Nothing is saved in static variables.</P
><P
>The static variables are managed like this.</P
><TABLE
BORDER="0"
BGCOLOR="#d0ffff"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="PROGRAMLISTING"
>val cf_server_config: ServerConfig option ref = ref NONE

val cf_nodes: NodeConfig list ref = ref []

fun getServerConfig()  = valOf(!cf_server_config)
fun haveServerConfig() = isSome(!cf_server_config)
fun getNodeConfigs()   = !cf_nodes


fun getServerRoot() =
let
    val ServerConfig{server_root, ...} = getServerConfig()
in
    server_root
end</PRE
></TD
></TR
></TABLE
><P
>The <TT
CLASS="COMPUTEROUTPUT"
>processConfig</TT
> function looks like this.</P
><TABLE
BORDER="0"
BGCOLOR="#d0ffff"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="PROGRAMLISTING"
>fun processConfig file : unit =
let
    (* show the warnings while processing *)
    val _ = Log.lowerLevel Log.Warn
    val sections = parse_config false file
in
    (* dump_sections sections; *)

    (*  Ensure that the server node is processed first to
        get the server root for the nodes' files.
    *)
    process_server_section sections;
    process_node_sections sections;

    process_mime_file();
    init_globals();
    ()
end
handle _ =&#62; (Log.flush(); raise FatalX)



(*  This pokes some config parameters into various modules in
    common. 
*)
and init_globals() =
let
    val ServerConfig {error_log, log_level, max_tmp_space, ...} =
            getServerConfig()
in
    (*  Don't change the error stream until the config has been processed. *)
    Log.flush();
    Log.setLogFile error_log;
    Log.setLevel   log_level;

    case max_tmp_space of
      NONE   =&#62; ()
    | SOME l =&#62; TmpFile.setDiskLimit l;

    ()
end</PRE
></TD
></TR
></TABLE
><P
>The log level needs to be lowered to make sure that warnings
from the configuration checking get through.  They will appear on
standard error. (The level could have been set higher by a command line
option).  Only after the configuration has been successfully read are
errors redirected to the log file.  Any exceptions are fatal.</P
><P
>The next sections describe the use of ML-Yacc and ML-Lex in detail for parsing
the configuration.</P
></DIV
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="DTLCONFIGGRM"
>The Configuration Grammar</A
></H2
><P
>The modules of an ML-Yacc parser are quite complex to describe as they
use multiple functors to assemble the parser from parts.  But it's easy to
copy from an example.  For the full details see the ML-Yacc documentation
that comes with the source package (see <A
HREF="a6548.html"
>Appendix C</A
>).</P
><P
>The parts of the parser are:</P
><P
></P
><UL
><LI
><P
>	A lexer generated by ML-Lex. This splits the input file into lexical tokens.</P
></LI
><LI
><P
>	The parsing tables generated by ML-Yacc. This includes modules
	that define the types and values for the lexical tokens.
	These are used by the lexer.</P
></LI
><LI
><P
>	The parsing algorithm which is part of the ML-Yacc library.</P
></LI
></UL
><P
>There is a lot of superficial similarity with a grammar file for
standard Unix C yacc.  One big difference is that it is even more
strongly recommended that the parsing be side-effect free.  I've seen
many people write yacc grammars with action code that goes updating data
structures or printing out error messages during the parsing operation.
This immediately clashes with any kind of back-tracking such as error
recovery. The well-known problems of putting action code in the middle
of a production are an example of this.</P
><P
>I always just use a parser to build a parse tree. I don't report semantic
errors until a later pass over the tree.  The ML-Yacc parser here does the
same. The action code attached to each production is just an expression
that builds a node (or fragment of a node) in the parse tree.  The ML-Yacc
parser attempts recovery from syntax errors to continue parsing for as
long as possible.  This works best if the action code has no side-effects.</P
><P
>Here is the top part of the grammar file.  It is structured like a the
C yacc grammar file.</P
><TABLE
BORDER="0"
BGCOLOR="#d0ffff"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="PROGRAMLISTING"
>open Common
open ConfigTypes

%%

%eop EOF 

(* %pos declares the type of positions for terminals.
   Each symbol has an associated left and right position. *)

%pos Common.SrcPos
%arg (file): string

%term   
          KW_SERVER
        | KW_NODE

        | SYM_SEMICOLON
        | SYM_COMMA
        | SYM_LBRACE
        | SYM_RBRACE
        | SYM_EQUALS
        | SYM_SWERVE

        | TOK_WORD of string
        | TOK_STRING of string 
        | TOK_INT of int 

        | EOF

%nonterm 
          start of Section list
        | section_list of Section list
        | section of Section 
        | part_list of SectionPart list
        | part of SectionPart 
        | literal_list of Literal list
        | literal of Literal 

%name Config

%noshift EOF
%pure
%verbose

%%</PRE
></TD
></TR
></TABLE
><P
>It starts off with a header containing any SML declarations you may
need for the rest of the grammar.  This is delimited by the <TT
CLASS="COMPUTEROUTPUT"
>%%</TT
>
characters.</P
><P
>Then comes SML type declarations for the terminals and non-terminals.
These must look like an SML datatype declaration.  The terminals become
the tokens for the lexer.  The non-terminals are type declarations for
the production rules of the grammar. The action code of the rules must
be expressions of these types.</P
><P
>The terminal declarations can carry data. Here for example both a word and
a string carry the text of the word or string. The difference between the
two is that strings are quoted since they may contain special characters
and unquoted words appear in special places in the grammar.</P
><P
>The <TT
CLASS="COMPUTEROUTPUT"
>KW_</TT
> terminals are keywords. They are reserved words that are
recognised specially by the lexer.  They mark the beginning of major
syntactic constructs.  Using reserved words helps to eliminate ambiguity
in the grammar. The <TT
CLASS="COMPUTEROUTPUT"
>SYM_</TT
> terminals are punctuation symbols.</P
><P
>The <TT
CLASS="COMPUTEROUTPUT"
>%eop</TT
> directive indicates which terminal marks the end of
the input. It will be the same as the token returned by the <TT
CLASS="COMPUTEROUTPUT"
>eof</TT
>
function in the lexer. It also needs to be repeated in the <TT
CLASS="COMPUTEROUTPUT"
>%noshift</TT
>
directive.</P
><P
>The <TT
CLASS="COMPUTEROUTPUT"
>%arg</TT
> directive declares an argument that will be passed into
the parser. I use this to pass in the file name for error messages. The
<TT
CLASS="COMPUTEROUTPUT"
>%name</TT
> directive provides a prefix for the names of the parser
modules.  The <TT
CLASS="COMPUTEROUTPUT"
>%pure</TT
> directive declares that all of the action
code is side-effect free.  If you don't include this then the parser will
work harder to compensate which will slow it down.  The <TT
CLASS="COMPUTEROUTPUT"
>%verbose</TT
>
directive tells ML-Yacc to dump the grammar rules to a <TT
CLASS="COMPUTEROUTPUT"
>.desc</TT
>
file. This can be useful for figuring out ambiguity problems but you
need to be fairly familiar with LALR parsers.</P
><P
>I've actually combined two grammars together, one for the server
configuration file and one for the <TT
CLASS="COMPUTEROUTPUT"
>.swerve</TT
> files.  They share
a lot of syntax.  Unfortunately ML-Yacc doesn't support more than one
start symbol.  I have to fake it by prepending a special symbol, called
<TT
CLASS="COMPUTEROUTPUT"
>SYM_SWERVE</TT
>, to the terminals from a .swerve file.  The parser
driver in the Config module will push the string &quot;\001\001\001&quot; onto
the front of a <TT
CLASS="COMPUTEROUTPUT"
>.swerve</TT
> file.  The lexer will recognise this
string as the <TT
CLASS="COMPUTEROUTPUT"
>SYM_SWERVE</TT
> symbol.  The parser will then switch to the
swerve grammar.</P
><P
>Before looking at the grammar here are the types for the parse tree.</P
><TABLE
BORDER="0"
BGCOLOR="#d0ffff"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="PROGRAMLISTING"
>structure ConfigTypes =
struct

    datatype Section = 
            SectServer of {
                parts:  SectionPart list,
                pos:    Common.SrcPos
                }

        |   SectNode of {
                path:   string,
                parts:  SectionPart list,
                pos:    Common.SrcPos
                }

        (*  This is for the contents of a .swerve file *)
        |   SectSwerve of {
                parts:  SectionPart list
                }

    and     SectionPart = SectionPart of {
                left:   string,
                right:  Literal list,
                pos:    Common.SrcPos
                }

    and     Literal =
                LitIsString of string * Common.SrcPos
            |   LitIsInt of int * Common.SrcPos
end</PRE
></TD
></TR
></TABLE
><P
>The result of parsing will be a list of sections. Each section contains
a list of parts and a part is a &quot;word = value&quot; pair.  Every node in
the parse tree is annotated with a source position. This gives the file
name, line number and column where the characters corresponding to the node
starts. Positions are used in error messages.</P
><P
>Here is the top part of the production section.</P
><TABLE
BORDER="0"
BGCOLOR="#d0ffff"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="PROGRAMLISTING"
>start:
        section_list                    (section_list)

    |   SYM_SWERVE
        part_list                       ([SectSwerve {
                                            parts = part_list
                                            }])

section_list:   
        section                         ([section])

    |   section_list 
        section                         (section_list @ [section])


section:
        KW_SERVER 
        SYM_LBRACE
        part_list
        SYM_RBRACE                      (SectServer {
                                            parts = part_list,
                                            pos   = KW_SERVERleft
                                            })
    |   KW_NODE 
        TOK_WORD
        SYM_LBRACE
        part_list
        SYM_RBRACE                      (SectNode {
                                            path  = TOK_WORD,
                                            parts = part_list,
                                            pos   = KW_NODEleft
                                            })</PRE
></TD
></TR
></TABLE
><P
>The parsing starts at the first non-terminal which I've called
<TT
CLASS="COMPUTEROUTPUT"
>start</TT
>.  If it's parsing a server configuration file then the syntax
is a list of sections.  For a <TT
CLASS="COMPUTEROUTPUT"
>.swerve</TT
> file it is a list of parts.</P
><P
>The action code computes a value for the non-terminal on the left-hand
side of a production. A non-terminal on the right-hand side of a
production can be used in the action code and it represents the value
of the non-terminal.  The notation <TT
CLASS="COMPUTEROUTPUT"
>KW_SERVERleft</TT
> refers to the
source position of the first character of the terminal <TT
CLASS="COMPUTEROUTPUT"
>KW_SERVER</TT
>.
The notation <TT
CLASS="COMPUTEROUTPUT"
>TOK_WORD</TT
> represents the value carried by the terminal
so it's a string variable.  For more information on all of this see the
ML-Yacc documentation.</P
><P
>Since the <TT
CLASS="COMPUTEROUTPUT"
>start</TT
> non-terminal has the type <TT
CLASS="COMPUTEROUTPUT"
>(Section list)</TT
>
its action code must be of this type.  So a <TT
CLASS="COMPUTEROUTPUT"
>.swerve</TT
> file will
produce a list containing the single SectSwerve section.  The production
for <TT
CLASS="COMPUTEROUTPUT"
>section_list</TT
> is a standard pattern for a list of one or more
things.  It's a simple bit of recursion. Note that since ML-Yacc does
LALR grammars it must be left-recursion.  This means the recursive call
to <TT
CLASS="COMPUTEROUTPUT"
>section_list</TT
> appears at the beginning of the second branch of
the production.  The section production just computes a tree node with
type <TT
CLASS="COMPUTEROUTPUT"
>Section</TT
>.</P
><P
>Here's the rest of the grammar.  It's quite straight-forward.</P
><TABLE
BORDER="0"
BGCOLOR="#d0ffff"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="PROGRAMLISTING"
>part_list:      
        part                            ([part])

    |   part_list 
        part                            (part_list @ [part])


part:
        TOK_WORD SYM_EQUALS
        literal_list
        SYM_SEMICOLON                   (SectionPart {
                                            left  = TOK_WORD,
                                            right = literal_list,
                                            pos   = TOK_WORDleft
                                            })


literal_list:   
        literal                         ([literal])

    |   literal_list 
        literal                         (literal_list @ [literal])


literal:
        TOK_STRING                      (LitIsString (TOK_STRING, TOK_STRINGleft))
    |   TOK_INT                         (LitIsInt (TOK_INT, TOK_INTleft))
    |   TOK_WORD                        (LitIsString (TOK_WORD, TOK_WORDleft))</PRE
></TD
></TR
></TABLE
></DIV
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="DTLCONFIGLEX"
>The Configuration Lexer</A
></H2
><P
>The lexer splits the configuration files up into tokens which are words,
strings, symbols and integers.  The main difference between words and
strings is that that strings can contain any special character so
they must be quoted. Words are allowed to contain just enough special
characters to form most of the file paths you're likely to want. The
symbols include punctuation and some reserved words.  The layout of the
files is free format with any amount of white space between the tokens.</P
><P
>The lexer is generated using ML-Lex.  Starting in the middle of the
<TT
CLASS="COMPUTEROUTPUT"
>config.lex</TT
> file are some declarations that are required to
interface with the parser.</P
><TABLE
BORDER="0"
BGCOLOR="#d0ffff"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="PROGRAMLISTING"
>    (*  These definitions are required by the parser.
        The lexer types are supplied by the grammar.
    *)

    type    pos = Common.SrcPos
    type    arg = string                (* type from %arg below *)

    type svalue = Tokens.svalue
    type ('a,'b) token = ('a,'b) Tokens.token
    type lexresult= (svalue,pos) token

    fun eof file = Tokens.EOF(get_pos file 0, get_pos file 0)

%%
%header (functor ConfigLexFun(structure Tokens: Config_TOKENS));</PRE
></TD
></TR
></TABLE
><P
>ML-Yacc will generate a structure which defines all of the tokens
that are passed from the lexer to the parser.  These are the terminals
of the grammar.  The words terminal and token are synonymous. You use
<TT
CLASS="COMPUTEROUTPUT"
>%header</TT
> to declare the lexer as a functor that takes the structure
as an argument, here called <TT
CLASS="COMPUTEROUTPUT"
>Tokens</TT
>.  Here is the signature for
the structure, from the <TT
CLASS="COMPUTEROUTPUT"
>config.grm.sig</TT
> file.</P
><TABLE
BORDER="0"
BGCOLOR="#d0ffff"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="PROGRAMLISTING"
>signature Config_TOKENS =
sig
type ('a,'b) token
type svalue
val EOF:  'a * 'a -&#62; (svalue,'a) token
val TOK_INT: (int) *  'a * 'a -&#62; (svalue,'a) token
val TOK_STRING: (string) *  'a * 'a -&#62; (svalue,'a) token
val TOK_WORD: (string) *  'a * 'a -&#62; (svalue,'a) token
val SYM_SWERVE:  'a * 'a -&#62; (svalue,'a) token
val SYM_EQUALS:  'a * 'a -&#62; (svalue,'a) token
val SYM_RBRACE:  'a * 'a -&#62; (svalue,'a) token
val SYM_LBRACE:  'a * 'a -&#62; (svalue,'a) token
val SYM_COMMA:  'a * 'a -&#62; (svalue,'a) token
val SYM_SEMICOLON:  'a * 'a -&#62; (svalue,'a) token
val KW_NODE:  'a * 'a -&#62; (svalue,'a) token
val KW_SERVER:  'a * 'a -&#62; (svalue,'a) token
end</PRE
></TD
></TR
></TABLE
><P
>All of the tokens are defined as functions that map from a pair of source
positions and possibly some contained value to the <TT
CLASS="COMPUTEROUTPUT"
>token</TT
> type.
There are two source positions so that you can point to the first
and last characters of the token in the source file.  I just point
to the first character and set the second position to be the same as
the first.  For example to generate the <TT
CLASS="COMPUTEROUTPUT"
>EOF</TT
> token I just call
the <TT
CLASS="COMPUTEROUTPUT"
>Tokens.EOF</TT
> function with some dummy source positions.</P
><P
>In the signature the <TT
CLASS="COMPUTEROUTPUT"
>'a</TT
> type variable represents whatever type you
choose for the source position.  The <TT
CLASS="COMPUTEROUTPUT"
>svalue</TT
> name means &quot;semantic
value&quot;. It's whatever data will be carried along with the tokens.
When used with an ML-Yacc parser it will also include the types for the
non-terminals. All you have to do is ensure that there are definitions for
the <TT
CLASS="COMPUTEROUTPUT"
>svalue</TT
> and <TT
CLASS="COMPUTEROUTPUT"
>token</TT
> types in the lexer which are equated
to the types supplied in the <TT
CLASS="COMPUTEROUTPUT"
>Tokens</TT
> structure. Also you must equate
the <TT
CLASS="COMPUTEROUTPUT"
>lexresult</TT
> type to be the same as the parser's token type.</P
><P
>Here is the bottom half of the <TT
CLASS="COMPUTEROUTPUT"
>config.lex</TT
> file which defines the
regular expressions for the tokens.</P
><TABLE
BORDER="0"
BGCOLOR="#d0ffff"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="PROGRAMLISTING"
>%%
%header (functor ConfigLexFun(structure Tokens: Config_TOKENS));
%full
%arg (file: string);

wrd1=[A-Za-z_/\\$:.%+-];
wrd=[A-Za-z0-9_/\\$:.%+-];
word={wrd1}{wrd}*;
str=([^"\n]|\\\n|\\\"|\\\\);
digit=[0-9];
int=[+-]?{digit}+;

ws=[\ \t\013];
%%

"\n"            =&#62; (new_line yypos; continue());
{ws}+           =&#62; (continue());
#.*\n           =&#62; (new_line yypos; continue());


{word}          =&#62; (check_reserved yytext file yypos);

{int}           =&#62; (fix_integer yytext file yypos);

\"{str}*\"      =&#62; (fix_str yytext file yypos);

";"             =&#62; (sym Tokens.SYM_SEMICOLON file yypos);
","             =&#62; (sym Tokens.SYM_COMMA file yypos);
"{"             =&#62; (sym Tokens.SYM_LBRACE file yypos);
"}"             =&#62; (sym Tokens.SYM_RBRACE file yypos);
"="             =&#62; (sym Tokens.SYM_EQUALS file yypos);
"\001\001\001"  =&#62; (sym Tokens.SYM_SWERVE file yypos);


.               =&#62; (Log.errorP (get_pos file yypos)
                ["Unrecognised characters in the configuration file."];
                    eof file);</PRE
></TD
></TR
></TABLE
><P
>The <TT
CLASS="COMPUTEROUTPUT"
>wrd</TT
> definition defines the characters that can appear in a
word. The <TT
CLASS="COMPUTEROUTPUT"
>wrd1</TT
> definition is the subset that can be the first
character of a word. This excludes digits to avoid confusion with
integers.  Strings can contain backslash escapes. Within the regular
expression a few have to be handled separately. The <TT
CLASS="COMPUTEROUTPUT"
>\\\n</TT
>
combination ensures that new-lines are only allowed if they are
immediately preceded by a backslash.  Similarly a double-quote is
allowed inside a string if it is preceded by a backslash.  The last
term ensures that the sequence <TT
CLASS="COMPUTEROUTPUT"
>&quot;foo\\&quot;</TT
> is correctly recognised as
a backslash at the end of a string and not a backslash followed by an
internal double-quote.</P
><P
>The &quot;\001\001\001&quot; is the three CTRL-A character marker that
is inserted at the beginning of a <TT
CLASS="COMPUTEROUTPUT"
>.swerve</TT
> file as described in
<A
HREF="x5681.html#DTLCONFIGGRM"
>the section called <I
>The Configuration Grammar</I
></A
>.</P
><P
>The lexer uses a few helper functions in the top section of the
<TT
CLASS="COMPUTEROUTPUT"
>config.lex</TT
> file to build a token.  For example the <TT
CLASS="COMPUTEROUTPUT"
>yytext</TT
>
variable contains the complete matched text which for strings will
include the double quote characters. The <TT
CLASS="COMPUTEROUTPUT"
>fix_str</TT
> function strips
them off and also translates the backslash escapes.</P
><TABLE
BORDER="0"
BGCOLOR="#d0ffff"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="PROGRAMLISTING"
>fun fix_str yytext file yypos =
let
    val pos = get_pos file yypos
    val chars = explode(substring(yytext, 1, size yytext - 2))

    fun count_nl [] pp = ()
    |   count_nl (#"\n"::rest) pp = (new_line pp; count_nl rest (pp+1))
    |   count_nl (c::rest) pp     = count_nl rest (pp+1)

    fun xlate [] rslt = implode(rev rslt)
    |   xlate (#"\\"::c::rest) rslt =
    let
        val nc =
            case c of
              #"n" =&#62; #"\n"
            | #"t" =&#62; #"\t"
            | _    =&#62; c
    in
        xlate rest (nc::rslt)
    end
    |   xlate (c::rest) rslt = xlate rest (c::rslt)
in
    count_nl chars (yypos+1);
    Tokens.TOK_STRING(xlate chars [], pos, pos)
end</PRE
></TD
></TR
></TABLE
><P
>According the <TT
CLASS="COMPUTEROUTPUT"
>Config_TOKENS</TT
> signature above the <TT
CLASS="COMPUTEROUTPUT"
>TOK_STRING</TT
>
function takes the text of the string as the first argument. The type for
this argument comes from the <TT
CLASS="COMPUTEROUTPUT"
>%term</TT
> declaration in the grammar file.</P
><P
>What's a little tricky is keeping track of the line and column positions.
I can count lines by being careful to call my <TT
CLASS="COMPUTEROUTPUT"
>new_line</TT
> function
(below) for each new-line character in a matched expression.  I've made
the new-line separate from the white space expression (<TT
CLASS="COMPUTEROUTPUT"
>ws</TT
>) to make
it easier to count. ML-Lex generates code to provide the position of a
matched regular expression as the character offset from the beginning
of the source.  This is available in the <TT
CLASS="COMPUTEROUTPUT"
>yypos</TT
> variable.  If I
save the offset of each new-line then I can work out the column number
of a character by subtracting the offset of the character from that of
the most recent new-line.  This is taken care of in the following code.</P
><TABLE
BORDER="0"
BGCOLOR="#d0ffff"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="PROGRAMLISTING"
>val     line = ref 1                (* current line *)
val     line_pos = ref 0            (* char position of preceding \n *)

fun get_pos file yypos =
let
    val col = Int.max(yypos - !line_pos, 1) (* see eof *)
in
    Common.SrcPos {file=file, line= (!line), col=col}
end


fun new_line yypos =
(
    line := !line + 1;
    line_pos := yypos
)</PRE
></TD
></TR
></TABLE
><P
>The <TT
CLASS="COMPUTEROUTPUT"
>count_nl</TT
> function in <TT
CLASS="COMPUTEROUTPUT"
>fix_str</TT
> above is needed to account
for new-line characters embedded in strings.  It has to track the source
position within the string to keep the positions right.</P
><P
>Integers as strings are converted to numeric values in the
<TT
CLASS="COMPUTEROUTPUT"
>fix_integer</TT
> function. The <TT
CLASS="COMPUTEROUTPUT"
>sym</TT
> function just adds source
positions to the symbols.  I won't show these here as they are simple
enough.  Reserved words are filtered out in the <TT
CLASS="COMPUTEROUTPUT"
>check_reserved</TT
>
function.</P
><TABLE
BORDER="0"
BGCOLOR="#d0ffff"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="PROGRAMLISTING"
>val reserved_words = [
    ("SERVER",      Tokens.KW_SERVER),
    ("NODE",        Tokens.KW_NODE)
    ]


fun check_reserved yytext file yypos =
let
    val uword = Common.upperCase yytext
    val pos = get_pos file yypos
in
    case List.find (fn (w, _) =&#62; w = uword) reserved_words of
      NONE          =&#62; Tokens.TOK_WORD(yytext, pos, pos)
    | SOME (_, tok) =&#62; tok(pos, pos)
end</PRE
></TD
></TR
></TABLE
><P
>Since there are only a few a search through a list is fine.  The word
matching is case-insensitive.</P
></DIV
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="DTLCONFIGDRV"
>The Parser Driver</A
></H2
><P
>This section completes the description of the parser by showing how it
is used in the Config module.  The various structures and functors are
assembled to make a complete parser as follows.</P
><TABLE
BORDER="0"
BGCOLOR="#d0ffff"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="PROGRAMLISTING"
>(*  Assemble the pieces to make a parser. *)

structure ConfigLrVals = ConfigLrValsFun(structure Token = LrParser.Token)
structure ConfigLex    = ConfigLexFun(structure Tokens = ConfigLrVals.Tokens)
structure ConfigParser = JoinWithArg(structure LrParser = LrParser
                        structure ParserData = ConfigLrVals.ParserData
                        structure Lex = ConfigLex)

(*  Max number of tokens to lookahead when correcting errors. *)
val max_lookahead = 15;     

(*  The syntax error messages use the token names. This is for editing
    them to something more readable.
*)
val syntax_edits = [
    ("KW_SERVER",       "Server"),
    ("KW_NODE",         "Node"),
    ("SYM_SEMICOLON",   "semicolon"),
    ("SYM_COMMA",       "comma"),
    ("SYM_LBRACE",      "'{'"),
    ("SYM_RBRACE",      "'}'"),
    ("SYM_EQUALS",      "'='"),
    ("TOK_WORD",        "word"),
    ("TOK_STRING",      "string"),
    ("TOK_INT",         "number")
    ]</PRE
></TD
></TR
></TABLE
><P
>The <TT
CLASS="COMPUTEROUTPUT"
>ConfigLrVals</TT
> structure contains the tables of parsing
operations for the grammar. The <TT
CLASS="COMPUTEROUTPUT"
>ConfigLex</TT
> structure contains
the complete lexer specialised with the types needed to communicate
with the parser.  The <TT
CLASS="COMPUTEROUTPUT"
>JoinWithArg</TT
> functor is part of the
ML-Yacc library.  It joins all the pieces together.  The &quot;WithArg&quot;
part of the name indicates that it supports an argument being passed
in at parsing time. I use this to carry the file name.  You can see
it in the <TT
CLASS="COMPUTEROUTPUT"
>%arg</TT
> declarations in the grammar and lexer files.
(The file argument isn't used in the parser but the way the joining
works it must be there if the lexer has one).</P
><P
>The result is a complete parser in the <TT
CLASS="COMPUTEROUTPUT"
>ConfigParser</TT
> structure
which will be used below.</P
><P
>A parser generated by ML-Yacc will do syntax correction. This means
that if there is a syntax error it will attempt to insert or delete
tokens to change the input into something parsable and then continue.
It will produce an error message showing what change it made which
should give the user an idea of what the original syntax error was.
This sounds clever but it can be confusing. It means that if you omit
a semicolon for example you will get an error message saying that one
was inserted.  This isn't very user-oriented.  What's worse is that the
tokens in the messages are described using the names that appear in the
grammar file.  I like to have distinctive terminal names in the grammar
file, in uppercase.  So I process the error messages to convert the
terminal names to something more readable.  The <TT
CLASS="COMPUTEROUTPUT"
>syntax_edits</TT
> list
in the above code is used for this processing. The <TT
CLASS="COMPUTEROUTPUT"
>max_lookahead</TT
>
parameter controls the error correction.  The value 15 is recommended
in the ML-Yacc documentation for most purposes.</P
><P
>Here is the <TT
CLASS="COMPUTEROUTPUT"
>parse_config</TT
> function which drives the parser.</P
><TABLE
BORDER="0"
BGCOLOR="#d0ffff"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="PROGRAMLISTING"
>and parse_config swerve file: Section list =
let
    fun parse_error(msg, pos1, pos2) = Log.errorP pos1 [edit_errors msg]

    val swerve_done = ref false

    fun input rstrm n =
    (
        if swerve andalso not (!swerve_done)
        then
            (swerve_done := true; "\^A\^A\^A")
        else
            TextIO.inputN(rstrm, n)
    )

    fun do_parser holder =
    let
        val rstrm = TextIOReader.get holder

        fun do_parse lexstream =
            ConfigParser.parse(max_lookahead, lexstream, parse_error, file)

        val in_stream = ConfigParser.makeLexer (input rstrm) file

        val (result, new_stream) = do_parse in_stream
                    handle ParseError =&#62; ([], in_stream)
    in
        TextIOReader.closeIt holder;
        result
    end
in
    case TextIOReader.openIt' file of
      NONE   =&#62; []
    | SOME h =&#62; do_parser h
end</PRE
></TD
></TR
></TABLE
><P
>The <TT
CLASS="COMPUTEROUTPUT"
>TextIOReader.openIt'</TT
> function opens the file without worrying
about connection time-outs.  The <TT
CLASS="COMPUTEROUTPUT"
>swerve</TT
> argument indicates that
a <TT
CLASS="COMPUTEROUTPUT"
>.swerve</TT
> file is being parsed.  The <TT
CLASS="COMPUTEROUTPUT"
>.swerve</TT
> files are
actually read while the server is processing connections so I should be
worrying about time-outs for them but the files are small so I'll get
away with it.</P
><P
>In the <TT
CLASS="COMPUTEROUTPUT"
>do_parser</TT
> function the parsing is run by a
call to the ConfigParser.parse function. The second argument to
<TT
CLASS="COMPUTEROUTPUT"
>ConfigParser.parse</TT
> is the lexer. The third is a call-back function
for error messages and the fourth is the <TT
CLASS="COMPUTEROUTPUT"
>%arg</TT
> argument value.
The lexer is made with the <TT
CLASS="COMPUTEROUTPUT"
>ConfigParser.makeLexer</TT
> function which
takes a source reading function and a <TT
CLASS="COMPUTEROUTPUT"
>%arg</TT
> argument value. The
<TT
CLASS="COMPUTEROUTPUT"
>input</TT
> function delivers the contents of the file in chunks of
size <TT
CLASS="COMPUTEROUTPUT"
>n</TT
>.  If it is a <TT
CLASS="COMPUTEROUTPUT"
>.swerve</TT
> file then the first chunk is
forced to be the triple CTRL-A marker.</P
><P
>I've omitted a description of the syntax error editing.  It's just some
straight-forward string manipulation.  The <TT
CLASS="COMPUTEROUTPUT"
>Substring.position</TT
>
function does the job of finding the string to replace.</P
><P
>The end-result of all of this is parse tree whose type is
<TT
CLASS="COMPUTEROUTPUT"
>ConfigTypes.Section list</TT
>, which is the type of the <TT
CLASS="COMPUTEROUTPUT"
>start</TT
>
non-terminal in the grammar.</P
></DIV
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="DTLCONFIGTREE"
>Processing the Parse Tree</A
></H2
><P
>The output from the parser is a list of sections of the type
<TT
CLASS="COMPUTEROUTPUT"
>ConfigTypes.Section</TT
>. The two main processing steps that follow
are for the server and node sections. Refer to the <TT
CLASS="COMPUTEROUTPUT"
>processConfig</TT
>
function in <A
HREF="x5681.html#DTLCONFIG"
>the section called <I
>The Config Module - Interface</I
></A
>.</P
><P
>The <TT
CLASS="COMPUTEROUTPUT"
>process_server_section</TT
> function looks through the
sections for the server configuration section. </P
><TABLE
BORDER="0"
BGCOLOR="#d0ffff"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="PROGRAMLISTING"
>and process_server_section sections =
let
    fun match (SectServer _) = true
    |   match _              = false

    val sects = List.filter match sections
in
    case sects of
      [SectServer {parts, ...}] =&#62; process_server_parts parts

    | [] =&#62; (Log.error
               ["A server configuration section must be supplied."];
             raise Bad)

    | _  =&#62; (Log.error
               ["There are multiple server configuration sections."];
             raise Bad)
end</PRE
></TD
></TR
></TABLE
><P
>The <TT
CLASS="COMPUTEROUTPUT"
>process_server_parts</TT
> function saves each parameter into the
static variables.  (This design neatly allows the server section to be
anywhere in the file).</P
><P
>The <TT
CLASS="COMPUTEROUTPUT"
>process_node_sections</TT
>
function finds each node section and adds it to the list of node
configurations in a static variable.  The static variables are described
in <A
HREF="x5681.html#DTLCONFIG"
>the section called <I
>The Config Module - Interface</I
></A
>.</P
><TABLE
BORDER="0"
BGCOLOR="#d0ffff"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="PROGRAMLISTING"
>and process_node_sections sections =
let
    fun process sect =
    (
        case process_node_section sect of
          NONE        =&#62; ()
        | SOME config =&#62; cf_nodes := config :: (!cf_nodes)
    )

    fun match (SectNode _) = true
    |   match _            = false

    val sects = List.filter match sections
in
    case sects of
      [] =&#62; (Log.log Log.Warn (TF.S
               "There are no node configuration sections."))

    | _  =&#62; app process sects
end</PRE
></TD
></TR
></TABLE
><P
>I won't describe the parameter processing in detail. It's a lot of
long-winded checking of values for the correct format and legality.
I'll just describe the general idea.</P
><P
>The <TT
CLASS="COMPUTEROUTPUT"
>process_server_parts</TT
> takes a list of
<TT
CLASS="COMPUTEROUTPUT"
>ConfigTypes.SectionPart</TT
> values which contain one parameter
each. It has two dispatch tables for string-valued and integer-valued
parts. These dispatch to functions that check the value and return the
value if it is legal.  If the value is illegal then an error message
is logged and the <TT
CLASS="COMPUTEROUTPUT"
>Bad</TT
> exception is raised. This is caught at
the top in <TT
CLASS="COMPUTEROUTPUT"
>processConfig</TT
> which aborts the whole server with a
<TT
CLASS="COMPUTEROUTPUT"
>FatalX</TT
> exception.</P
><P
>Each dispatch step reduces the list of parts by removing those that
are recognised.  If there are any parts left over then they must
be unrecognised parameters and error messages are logged. (See the
<TT
CLASS="COMPUTEROUTPUT"
>unrec_param</TT
> function).</P
><P
>The server configuration record is built up from the successful values
returned from the dispatch functions.  Utility functions are used to
extract particular parameters. For example the <TT
CLASS="COMPUTEROUTPUT"
>reqstr</TT
> function
finds a required parameter that has a string value.  Defaulting is
performed at this stage.</P
><P
>Node section processing is similar but since there are fewer parameters
and their types are more complex there isn't a formal dispatch table.
There isn't as much checking for legality as there should be. For example
I don't check that the name of a built-in handler is legal at this stage,
nor if a CGI script exists.</P
></DIV
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="DTLCONFIGMIME"
>MIME Type Configuration</A
></H2
><P
>The server configuration contains the path to the MIME types file. This
has the same format as is used by Apache.  The contents of this file is
read in by the <TT
CLASS="COMPUTEROUTPUT"
>process_mime_file</TT
> function and saved into a table.
The table maps from a file extension to a pair of major/minor MIME
type names. For case-insensitivity the extensions are saved in upper case.</P
><TABLE
BORDER="0"
BGCOLOR="#d0ffff"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="PROGRAMLISTING"
>(*  The mime information is just a map from an extension to
    the pair.
*)
val mime_table: (string * string) STRT.hash_table =
                                    STRT.mkTable(101, NotFound)</PRE
></TD
></TR
></TABLE
><P
>There is only one external API function, <TT
CLASS="COMPUTEROUTPUT"
>lookupMime</TT
>.</P
><TABLE
BORDER="0"
BGCOLOR="#d0ffff"
WIDTH="100%"
><TR
><TD
><PRE
CLASS="PROGRAMLISTING"
>and process_mime_file() =
let
    val ServerConfig {mime_file, ...} = getServerConfig()
in
    if Files.readableReg mime_file
    then
        FileIO.withTextIn (Abort.never())
            mime_file () (read_mime mime_file)
    else
        Log.error ["The MIME types file is not readable: ", mime_file]
end



and read_mime mime_file stream : unit =
let
    fun loop lnum =
    (
        case TextIO.inputLine stream of
          "" =&#62; ()
        | line =&#62; (do_line lnum line; loop (lnum+1))
    )
... omitted material ...
in
    loop 1
end


and lookupMime ext = STRT.find mime_table (upperCase ext)</PRE
></TD
></TR
></TABLE
></DIV
></DIV
><DIV
CLASS="NAVFOOTER"
><HR
ALIGN="LEFT"
WIDTH="100%"><TABLE
WIDTH="100%"
BORDER="0"
CELLPADDING="0"
CELLSPACING="0"
><TR
><TD
WIDTH="33%"
ALIGN="left"
VALIGN="top"
><A
HREF="x5496.html"
>Prev</A
></TD
><TD
WIDTH="34%"
ALIGN="center"
VALIGN="top"
><A
HREF="index.html"
>Home</A
></TD
><TD
WIDTH="33%"
ALIGN="right"
VALIGN="top"
><A
HREF="x5914.html"
>Next</A
></TD
></TR
><TR
><TD
WIDTH="33%"
ALIGN="left"
VALIGN="top"
>The IETF Layer</TD
><TD
WIDTH="34%"
ALIGN="center"
VALIGN="top"
><A
HREF="c4671.html"
>Up</A
></TD
><TD
WIDTH="33%"
ALIGN="right"
VALIGN="top"
>The Common Layer</TD
></TR
></TABLE
></DIV
></BODY
></HTML
>
